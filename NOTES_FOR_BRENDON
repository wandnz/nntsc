To the config file (myconf.conf), I have added the following section:

# Options for connection settings and database info of influxdb 
[influx]
useinflux = yes
database = nntsc
username =
password =
host = localhost
port = 8186
keepdata = 30d
keeprollups = 365d

Should be self explanatory but...

Useinflux - whether or not to use influxdb for some amp modules
database - name of influx database (we assume that it exists, created with influx command "CREATE DATABASE <database>")
username - username if username is required for database (https://docs.influxdata.com/influxdb/v0.10/administration/authentication_and_authorization/)
password - password, see above
host - host of influxdb
port - port influxdb is being hosted on (default is 8086, but I'm using 8186 - see /etc/influxdb/influxdb.conf)
keepdata - how long to keep raw data
keeprollups - how long to keep aggregated data (these translate to retention policies https://docs.influxdata.com/influxdb/v0.10/guides/downsampling_and_retention/)

The keepdata and keeprollups options are only used on build, so to adjust these you must rerun the build. They have to match ([0-9]+[smhd])|inf - 'inf' means don't drop old data

Information about backup and restore - https://docs.influxdata.com/influxdb/v0.10/administration/backup_and_restore/ Use this to backup data to a second disk or something before it gets thrown away


Edits to the code:

I have created a new file lib/influx.py which contains the following classes:

InfluxConnection(object):
	A generic connection to the influx database. Relies on influxdb library. It contains a method for general queries, one to query the first or last timestamp in a series, one to handle
	exceptions (which probably needs improving), and a couple of useful conversion functions for getting binsizes in seconds for influx binsizes of form [0-9]+[smhd] and vice versa.
	The other classes in this file inherit from this class

ContinuousQueryRerunner(Thread):
	A thread object for rerunning a continuous query in the background while continuing to insert points. Created and used by InfluxInsertor in commit_data() method

InfluxInsertor(InfluxConnection):
	Used for inserting data into the database. Also used by build script for creating continuous queries and retention policies, or refreshing the database if -f option is used.
	insert_data only maintains a list of points to be inserted, which aren't actually inserted until commit_data is run. If the data is old, these methods keep track of which points need to be
	wrapped up into aggregations through the points_windows member variable. This is a dictionary of tables with tuples of the timestamps of first item that's been inserted in that table this session,
	the last item, and a dictionary of which bins have already been wrapped up. Once one bin has been filled, commit_data() will run an aggregation query on the last two bins in that table to wrap them
	up.
	The continuous query methods use a couple of helper functions defined in a second file called cqs.py. These functions are seperated to avoid circular inheritance, 
	as they use the amp modules, which in turn use influx.py. This could possibly be redesigned. InfluxInsertor also keeps track of which continuous queries are in the database via cqs_in_db, which is
	used by multiple functions here.
	create_retention_policies() creates two retention policies called "default" and "rollups" which are defined as static variables DEFUALT_RP and ROLLUP_RP

InfluxSelector(InfluxConnection):
	Used for selecting data from the influx database. Perhaps this should be put in a separate file?
	Main two functions are select_data() and select_aggregated_data(). These are actually called by the identically named functions in lib/db_select.py. This is because the same sanitisation and
	schema stuff needs to be done either way, and as this code was located in the original functions I thought it would be easier this way, but it feels pretty messy. These functions could definitely
	be decoupled if you wanted tidier code. What happens is that if the original function is called with an instance of an InfluxSelector, it will call it's counterpart in that instance, 
	otherwise it'll carry on and select the data from postgres.
	
	What these functions do in influx is the following:
		1. For select_aggregated_data, work out if we are querying pre-aggregated data or not by asking the following questions:
			- how recent is the query (will it be aggregated yet)
			- Do we have a table which is the right table and binsize for this query?
			- Does that table have all of the aggregation columns that we're asking for?
		2. Construct a query to get the data we want. Some special cases:
			- If there's no pre-aggregated table we need to run the aggregation functions on the original table
			- If there is a pre-aggregated table, we need to request the aggregated column names, get these from the amp modules (each has a member variable called 'cqs' which tracks this info)
			- If we want a smoke array, request percentiles
			- If we want an 'avg', request 'mean'
		3. Run the query on the database
		4. Clean up each row to be returned:
			- Take percentiles and wrap up into smoke array - bit of fudging here, if there is less than 20 results take 100/n, (100/n)*2 ... (100/n)*n percentile (sort of)
			- If there are multiple aggregations on one column, label appropriately
			- Make sure there is a timestamp, an binstart and a min_timestamp (I fudge this by making them all identical, as influx only returns one, doesn't seem to make a difference.)
			- Add an 'nntsclabel', which is just the label that we were querying
		5. If it was an aggregate function and used a pre-aggregated table, we won't have got the most recent data, so do a separate query for that
	`	6. Loop through and yield results until we run out

Other than this, most significant change (as mentioned above) is the new member variables of each amp module, cqs and influxdb, which keep track of a list of continuous queries to run on that database, and an instance of an InfluxInsertor for inserting data into that database. These will call insert_data() on that InfluxInsertor if it exists instead of on the postgres alternative. This happens in common.py, insert_data(), then commit is called on the appropriate database (one or both) in amp.py, process_data()

InfluxDB:

	As mentioned above, config file is in /etc/influxdb/influxdb.conf. Helpful options here:
	
[meta]
dir = <where you want meta data stored>
the rest of these options are mostly to do with clustering (multiple servers), so probably don't worry about them, although it's a good idea to change the 'hostname' to the name of the machine influx is running on before you start

[data]
dir = <where you want data to be stored>
other options are pretty well documented in the config file itself. WAL stands for write ahead log, and TSM stands for tree sort merge. TSM is the default storage engine for InfluxDB at the time of writing.

[retention]
enabled = true
check-interval = <how often you want to check if you need to throw out old data>

[http]
enabled = true
bin-address = ":<port>"
other stuff for authentication and is here

[continuous_queries]
enabled = true
run-interval = "<how often you want to check if CQs need to be run>"

You can always get the latest version of influx here https://influxdata.com/downloads/#influxdb

Once you've downloaded it, run the following command to start it up

sudo influxd -config /etc/influxdb/influxdb.conf (assuming this is where you are storing your config file)

You can then use the CLI to access influx directly with the command

influx -port <port_num>

On a fresh install, create a new database with the influx command

CREATE DATABASE <db_dbname>

If you want to use a particular database, use the influx query

USE <db_name>

You can then run queries on this database. Documentation is here -> https://docs.influxdata.com/influxdb/v0.10/query_language/data_exploration/

A few helpful queries

show measurements:
	shows all the measurements (tables) that exist

show field keys from <measurement>
	shows all the names of the fields in a given measurement

show tag values from <measurement> with key = stream
	shows all the unique streams for a given measurement
	(Data is stored so that 'time' and 'stream' are "tags" and everything else is a "field")

show shards:
	gives some insight into the underlying storage structure of the database. Different shard groups have time ranges and are either for raw data or rollups.

show retention policies on <db_name>
	Shows the retention policies on database, which one is the default, how long they last and how many times they are replicated (for clustering)
	Nb. to query a rollup table, you need to explictly query rollups.<rollup_measurement>. This is because rollups is not the default retention policy. It is possible
	to store data on two different retention policies in the same measurement, so simply querying select x from <rollup_measurement> will give you an empty result (all of
	the results in <rollup_measurement> that belong to the default retention policy, which is 0)

help:
	Well yeah, you can probably work out what this does :)


Any other questions, my email is andy.belltree@gmail.com.
